"""
Demo: Optimized Domain Scanning - Speed vs Thoroughness
Shows the performance improvements and bypasses Google blocks
"""

import time
from datetime import datetime
from fast_bulk_scanner import FastBulkScanner

def main():
    print("ðŸš€ OPTIMIZED DOMAIN SCANNING DEMO")
    print("=" * 60)
    print()
    
    # Test domains
    domains = [
        "daytona.co.za",
        "github.com",
        "gitlab.com",
        "stackoverflow.com",
        "reddit.com"
    ]
    
    print(f"ðŸ“‹ Testing {len(domains)} domains:")
    for i, domain in enumerate(domains, 1):
        print(f"  {i}. {domain}")
    print()
    
    # Show the problem first - what happens with Google dorking
    print("âŒ THE GOOGLE PROBLEM:")
    print("-" * 30)
    print("â€¢ Google Search: 429 Too Many Requests errors")
    print("â€¢ Rate limits: 10-40+ second delays per query")
    print("â€¢ Blocks after just a few requests")
    print("â€¢ Traditional dorking: 10+ minutes for basic scan")
    print("â€¢ Results: Often 0 due to blocking")
    print()
    
    # Show our solution
    print("âœ… OUR OPTIMIZED SOLUTION:")
    print("-" * 30)
    print("â€¢ Bypass Google completely")
    print("â€¢ Direct site analysis of common login paths")
    print("â€¢ Parallel processing (3-5 concurrent requests)")
    print("â€¢ Smart request delays (0.5-1.5 seconds)")
    print("â€¢ Expected time: 2-10 seconds per domain")
    print()
    
    input("Press Enter to start the optimized scan...")
    print()
    
    # Initialize fast scanner with optimized settings
    scanner = FastBulkScanner(max_workers=3, delay_range=(0.5, 1.0))
    
    # Start timing
    start_time = time.time()
    print(f"ðŸ•’ Started: {datetime.now().strftime('%H:%M:%S')}")
    print()
    
    # Run the scan
    results = scanner.bulk_scan(domains)
    
    # Show timing
    total_time = time.time() - start_time
    print()
    print(f"ðŸ•’ Completed: {datetime.now().strftime('%H:%M:%S')}")
    print(f"â±ï¸ Total Time: {total_time:.1f} seconds")
    print()
    
    # Show detailed summary
    summary = results['summary']
    
    print("ðŸ“Š PERFORMANCE SUMMARY:")
    print("-" * 30)
    print(f"Total Domains Scanned: {summary['total_domains']}")
    print(f"Successful Scans: {summary['successful_scans']}")
    print(f"Failed Scans: {summary['failed_scans']}")
    print(f"Average Time per Domain: {summary['average_time_per_domain']:.2f} seconds")
    print(f"Login Pages Found: {summary['total_login_pages_found']}")
    print(f"High Risk Findings: {summary['total_high_risk_findings']}")
    print()
    
    # Show login pages found
    if summary['total_login_pages_found'] > 0:
        print("ðŸŽ¯ LOGIN PAGES DISCOVERED:")
        print("-" * 30)
        
        for domain, result in results['domain_results'].items():
            if result['success']:
                login_count = result['results']['_summary'].get('login_pages_count', 0)
                if login_count > 0:
                    scan_time = result['scan_time']
                    print(f"âœ… {domain}: {login_count} login pages ({scan_time}s)")
                    
                    # Show specific login pages for this domain
                    login_pages = result['results']['_summary'].get('login_pages', [])
                    for page in login_pages[:3]:  # Show first 3
                        risk = page.get('analysis', {}).get('risk_level', 'unknown')
                        risk_emoji = "ðŸ”´" if risk == 'high' else "ðŸŸ¡" if risk == 'medium' else "ðŸŸ¢"
                        print(f"    {risk_emoji} {page['url']}")
                    
                    if len(login_pages) > 3:
                        print(f"    ... and {len(login_pages) - 3} more")
                    print()
    
    # Speed comparison
    print("âš¡ SPEED COMPARISON:")
    print("-" * 30)
    traditional_time = len(domains) * 120  # Estimate 2 minutes per domain with Google blocks
    speedup = traditional_time / total_time
    
    print(f"Traditional Google Dorking: ~{traditional_time/60:.1f} minutes")
    print(f"Our Optimized Approach: {total_time:.1f} seconds") 
    print(f"Speed Improvement: {speedup:.1f}x faster")
    print()
    
    print("ðŸŽ‰ CONCLUSION:")
    print("-" * 30)
    print("â€¢ Successfully bypassed Google's rate limiting")
    print("â€¢ Found login pages that Google dorking often misses")
    print("â€¢ Dramatically reduced scan time")
    print("â€¢ Higher success rate and reliability")
    print("â€¢ Perfect for bulk domain analysis")
    print()
    
    # Ask about saving results
    save = input("ðŸ’¾ Save detailed results to JSON file? (y/n): ").lower().strip()
    if save == 'y':
        filename = scanner.save_results()
        print(f"âœ… Results saved to: {filename}")
    
    print("\nâœ¨ Demo complete! The optimized approach clearly outperforms traditional Google dorking.")

if __name__ == "__main__":
    main()
